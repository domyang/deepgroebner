{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgroebner.networks import ParallelEmbeddingLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"Return calculated vectors and attention weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : `Tensor` of type `tf.float32' and shape (..., dq, d1)\n",
    "        Tensor of queries as rows.\n",
    "    K : `Tensor` of type `tf.float32` and shape (..., dkv, d1)\n",
    "        Tensor of keys as rows.\n",
    "    V : `Tensor` of type `tf.float32` and shape (..., dkv, d2)\n",
    "        Tensor of values as rows.\n",
    "    mask : `Tensor of type `tf.bool' and shape (..., 1, dkv)\n",
    "        The mask representing valid key/value rows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output : `Tensor` of type `tf.float32` and shape (..., dq, d2)\n",
    "        Processed batch of Q, K, V.\n",
    "    attention_weights : `Tensor` of type `tf.float32` and shape (..., dq, dkv)\n",
    "        Attention weights from intermediate step.\n",
    "\n",
    "    \"\"\"\n",
    "    QK = tf.matmul(Q, K, transpose_b=True)\n",
    "    d = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "    attention_logits = QK / tf.math.sqrt(d)\n",
    "    if mask is not None:\n",
    "        attention_logits += tf.cast(~mask, tf.float32) * -1e9\n",
    "    attention_weights = tf.nn.softmax(attention_logits)\n",
    "    output = tf.matmul(attention_weights, V)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPoolingLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super(AttentionPoolingLayer, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.Wk = tf.keras.layers.Dense(dim)\n",
    "        self.Wv = tf.keras.layers.Dense(dim)\n",
    "        self.dense = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.Q = self.add_weight(name='query',\n",
    "                                 shape=[1, self.dim],\n",
    "                                 initializer='glorot_normal')\n",
    "        super(AttentionPoolingLayer, self).build(batch_input_shape)\n",
    "\n",
    "    def call(self, batch, mask=None):\n",
    "        K = self.Wk(batch)\n",
    "        V = self.Wv(batch)\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "        X, attn_weights = scaled_dot_product_attention(self.Q, K, V, mask=mask)\n",
    "        return tf.squeeze(self.dense(X), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = AttentionPoolingLayer(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.06788629, 0.57301205, 0.04953672, 0.34167394, 0.33334586,\n",
       "         0.5058849 , 0.745126  , 0.959517  ],\n",
       "        [0.8084456 , 0.8914087 , 0.30999458, 0.8740726 , 0.15012875,\n",
       "         0.5063418 , 0.76032823, 0.5649372 ],\n",
       "        [0.80377656, 0.90998304, 0.98673   , 0.8215631 , 0.48435026,\n",
       "         0.64458954, 0.16177076, 0.09962187],\n",
       "        [0.59020656, 0.9020649 , 0.46243715, 0.14894478, 0.62541765,\n",
       "         0.357886  , 0.93383676, 0.91721267],\n",
       "        [0.6725505 , 0.03963019, 0.25039616, 0.9717347 , 0.4407414 ,\n",
       "         0.43552145, 0.47752053, 0.6523828 ],\n",
       "        [0.28118044, 0.64923483, 0.04277411, 0.550966  , 0.43449387,\n",
       "         0.48481938, 0.7963205 , 0.6660466 ],\n",
       "        [0.64957374, 0.27097702, 0.2389206 , 0.9549677 , 0.43790942,\n",
       "         0.36531553, 0.5649379 , 0.8762377 ],\n",
       "        [0.40529162, 0.96557724, 0.1817433 , 0.06427106, 0.63150704,\n",
       "         0.46903282, 0.7546195 , 0.7125125 ],\n",
       "        [0.9801216 , 0.6511995 , 0.5362876 , 0.43970835, 0.13224849,\n",
       "         0.7744161 , 0.7805253 , 0.41839033],\n",
       "        [0.14745858, 0.13213772, 0.5500001 , 0.32420376, 0.49161237,\n",
       "         0.85757065, 0.3475221 , 0.01946309]],\n",
       "\n",
       "       [[0.0129378 , 0.99489737, 0.6656905 , 0.21133178, 0.94287753,\n",
       "         0.59494704, 0.37463558, 0.684748  ],\n",
       "        [0.5264277 , 0.0177911 , 0.17606768, 0.22478624, 0.28093538,\n",
       "         0.7442922 , 0.650563  , 0.16974163],\n",
       "        [0.62833554, 0.51290184, 0.59677356, 0.6373821 , 0.6325794 ,\n",
       "         0.44057283, 0.9030255 , 0.4138022 ],\n",
       "        [0.21922825, 0.8596932 , 0.3992044 , 0.84614265, 0.77692777,\n",
       "         0.7551818 , 0.29471752, 0.91474557],\n",
       "        [0.77456564, 0.11905128, 0.11107894, 0.6575359 , 0.35148343,\n",
       "         0.3498036 , 0.8064925 , 0.9727605 ],\n",
       "        [0.13944429, 0.249434  , 0.63403636, 0.40917438, 0.6233809 ,\n",
       "         0.71436965, 0.9023116 , 0.3977992 ],\n",
       "        [0.18008108, 0.89862454, 0.06077652, 0.07910848, 0.4774164 ,\n",
       "         0.2650297 , 0.37784734, 0.23319395],\n",
       "        [0.13497007, 0.59845275, 0.38328078, 0.40981862, 0.3409752 ,\n",
       "         0.08875415, 0.93539864, 0.17649405],\n",
       "        [0.10242498, 0.25024503, 0.6643286 , 0.4899873 , 0.79411   ,\n",
       "         0.2044467 , 0.03914401, 0.15199928],\n",
       "        [0.88507086, 0.35356274, 0.02134208, 0.9971676 , 0.2566014 ,\n",
       "         0.7685433 , 0.00786954, 0.64049727]],\n",
       "\n",
       "       [[0.92568433, 0.2517754 , 0.12334452, 0.5695232 , 0.741768  ,\n",
       "         0.2500562 , 0.7247883 , 0.64940965],\n",
       "        [0.45662966, 0.29825008, 0.6995437 , 0.5775883 , 0.01621501,\n",
       "         0.2830804 , 0.45503974, 0.9861537 ],\n",
       "        [0.83950025, 0.74346715, 0.40472403, 0.9574507 , 0.11008748,\n",
       "         0.7931225 , 0.6877049 , 0.3792766 ],\n",
       "        [0.20713358, 0.61716014, 0.23398726, 0.2622895 , 0.22311838,\n",
       "         0.62289983, 0.34147605, 0.12600252],\n",
       "        [0.41607738, 0.14711994, 0.03916736, 0.45563325, 0.61860687,\n",
       "         0.15789211, 0.530056  , 0.91567093],\n",
       "        [0.7843878 , 0.3539295 , 0.9288786 , 0.14979315, 0.8866987 ,\n",
       "         0.52497107, 0.29788494, 0.06492425],\n",
       "        [0.57032984, 0.3792497 , 0.9045937 , 0.8426514 , 0.7052774 ,\n",
       "         0.31178775, 0.93004453, 0.6402429 ],\n",
       "        [0.7623378 , 0.51780236, 0.47337905, 0.47980294, 0.49496233,\n",
       "         0.66430855, 0.342798  , 0.71139044],\n",
       "        [0.8106677 , 0.7718806 , 0.9991806 , 0.9871771 , 0.23602569,\n",
       "         0.5867533 , 0.0817457 , 0.5411372 ],\n",
       "        [0.7012101 , 0.8039033 , 0.5911896 , 0.9395194 , 0.17104767,\n",
       "         0.75976044, 0.7461278 , 0.39149612]]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.random.rand(3, 10, 8).astype(np.float32)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-0.4520214 ],\n",
       "       [-0.48208076],\n",
       "       [-0.38833997]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
