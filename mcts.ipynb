{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgroebner.wrapped import CLeadMonomialsEnv as LeadMonomialsEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(epsilon=0.09):\n",
    "    \"\"\"Return an epsilon-greedy tree policy.\"\"\"\n",
    "    def policy(node):\n",
    "        if random.random() < epsilon:\n",
    "            return random.choice(node.children)\n",
    "        else:\n",
    "            return max(node.children, key=lambda n: n.value[node.env.turn])\n",
    "    return policy\n",
    "\n",
    "\n",
    "def ucb(c=np.sqrt(2)):\n",
    "    \"\"\"Return an upper confidence bound tree policy.\"\"\"\n",
    "    def policy(node):\n",
    "        def v(n):\n",
    "            if n.visits == 0:\n",
    "                return np.inf\n",
    "            else:\n",
    "                return n.value[node.env.turn] + c * np.sqrt(np.log(node.visits)/n.visits)\n",
    "        return max(node.children, key=v)\n",
    "    return policy\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"A tree node for Monte Carlo tree search.\"\"\"\n",
    "\n",
    "    def __init__(self, parent, action, reward, env):\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.env = env\n",
    "        self.visits = 0\n",
    "        self.value = np.zeros(env.players)\n",
    "\n",
    "\n",
    "class MCTSAgent:\n",
    "    \"\"\"A Monte Carlo tree search agent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tree_policy : function\n",
    "        A function which maps node to child node.\n",
    "    timeout : float, optional\n",
    "        The amount of time in seconds to perform rollouts before choosing an action.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tree_policy=ucb(), timeout=1.0):\n",
    "        self.tree_policy = tree_policy\n",
    "        self.timeout = timeout\n",
    "        self.root = None\n",
    "\n",
    "    def act(self, env):\n",
    "        \"\"\"Return a chosen action for the env.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        env : environment\n",
    "            The current environment.\n",
    "\n",
    "        \"\"\"\n",
    "        self.root = self.find_root(env)\n",
    "        limit = time.time() + self.timeout\n",
    "        while time.time() < limit:\n",
    "            leaf = self.expand(self.root)\n",
    "            value = self.simulate(leaf)\n",
    "            self.backup(leaf, value)\n",
    "        return max(self.root.children, key=lambda node: node.visits).action\n",
    "\n",
    "    def expand(self, node):\n",
    "        \"\"\"Return an unvisited or terminal leaf node following the tree policy.\n",
    "\n",
    "        Before returning, this function performs all possible actions from the\n",
    "        leaf node and adds new nodes for them to the tree as children of the\n",
    "        leaf node.\n",
    "        \"\"\"\n",
    "        while node.visits != 0 and len(node.children) > 0:\n",
    "            node = self.tree_policy(node)\n",
    "        if not node.env.done:\n",
    "            for action in node.env.actions:\n",
    "                env = node.env.copy()\n",
    "                _, reward, _, _ = env.step(action)\n",
    "                node.children.append(TreeNode(node, action, reward, env))\n",
    "        return node\n",
    "\n",
    "    def simulate(self, node):\n",
    "        \"\"\"Return one total reward from node following uniform random policy.\"\"\"\n",
    "        env = node.env.copy()\n",
    "        total_rewards = np.zeros(env.players)\n",
    "        while not env.done:\n",
    "            action = random.choice(env.actions)\n",
    "            _, rewards, _, _ = env.step(action)\n",
    "            total_rewards += rewards\n",
    "        return total_rewards\n",
    "\n",
    "    def backup(self, node, value):\n",
    "        \"\"\"Backup the return from a rollout from node.\"\"\"\n",
    "        while node is not None:\n",
    "            value += node.reward\n",
    "            node.visits += 1\n",
    "            node.value = (node.visits - 1)/node.visits * node.value + value/node.visits\n",
    "            node = node.parent\n",
    "\n",
    "    def find_root(self, env):\n",
    "        \"\"\"Return node corresponding to env in current tree using BFS.\"\"\"\n",
    "        if self.root is not None:\n",
    "            q = deque(self.root.children)\n",
    "            while q:\n",
    "                node = q.popleft()\n",
    "                if node.env == env:\n",
    "                    return node\n",
    "                q.extend(node.children)\n",
    "        return TreeNode(None, None, np.zeros(env.players), env)\n",
    "\n",
    "\n",
    "class MCTSWrapper:\n",
    "    \"\"\"A wrapper for LeadMonomialsEnv environments to interact with the MCTSAgent.\"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.players = 1\n",
    "        self.turn = 0\n",
    "        self.state = None\n",
    "        self.done = None\n",
    "        self.actions = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.env.reset()\n",
    "        self.done = False\n",
    "        self.actions = list(range(len(self.state)))\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state, reward, self.done, info = self.env.step(action)\n",
    "        self.actions = list(range(len(self.state)))\n",
    "        return self.state, reward, self.done, info\n",
    "\n",
    "    def copy(self):\n",
    "        copy = MCTSWrapper(self.env.copy())\n",
    "        copy.state = self.state.copy()\n",
    "        copy.done = self.done\n",
    "        copy.actions = self.actions.copy()\n",
    "        return copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-38.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MCTSWrapper(LeadMonomialsEnv('cyclic-4'))\n",
    "env.reset()\n",
    "env.env.value(gamma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = MCTSAgent(timeout=10)\n",
    "agent.act(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-36.00814578])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.root.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_random_performance(env, seed, samples):\n",
    "    \"\"\"Return best total return from random agent on env over given samples.\"\"\"\n",
    "    best = -np.inf\n",
    "    for _ in range(samples):\n",
    "        env.seed(seed)\n",
    "        env.reset()\n",
    "        best = max(best, env.value('random', gamma=1.0))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40min 25s, sys: 18.5 ms, total: 40min 25s\n",
      "Wall time: 40min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "env = LeadMonomialsEnv('3-20-10-weighted')\n",
    "weighted_returns = [best_random_performance(env, seed, 1000)\n",
    "                    for seed in np.random.randint(1000, size=10_000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-56.9911, 17.585136359721524)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(weighted_returns), np.std(weighted_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 38min 29s, sys: 260 ms, total: 1h 38min 30s\n",
      "Wall time: 1h 38min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "env = LeadMonomialsEnv('3-20-10-uniform')\n",
    "uniform_returns = [best_random_performance(env, seed, 1000)\n",
    "                   for seed in np.random.randint(1000, size=10_000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-104.4735, 32.71985785039415)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(uniform_returns), np.std(uniform_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 45min 38s, sys: 488 ms, total: 2h 45min 39s\n",
      "Wall time: 2h 45min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "env = LeadMonomialsEnv('3-20-10-maximum')\n",
    "maximum_returns = [best_random_performance(env, seed, 1000)\n",
    "                   for seed in np.random.randint(1000, size=10_000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-334.6879, 88.4650049092295)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(maximum_returns), np.std(maximum_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(agent, env):\n",
    "    env.reset()\n",
    "    total_reward = 0.0\n",
    "    while not env.done:\n",
    "        action = agent.act(env)\n",
    "        _, reward, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = MCTSAgent(timeout=1)\n",
    "env = MCTSWrapper(LeadMonomialsEnv('3-20-10-uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-62.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(agent, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
